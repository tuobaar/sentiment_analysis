{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":4140,"sourceType":"datasetVersion","datasetId":2477},{"sourceId":9819040,"sourceType":"datasetVersion","datasetId":6020345}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Load libraries\nimport pandas as pd\nimport joblib\nimport re\nimport nltk\nimport os\nimport tensorflow as tf\n\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import wordnet\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras import mixed_precision\n\n# Check for GPU availability\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n# Optionally, use mixed precision for faster training on GPU\npolicy = mixed_precision.Policy('mixed_float16')\nmixed_precision.set_global_policy(policy)\n\n# Manually specify the path to NLTK data\nnltk_data_path = '/usr/share/nltk_data'  # This is the default location for Kaggle\nos.environ['NLTK_DATA'] = nltk_data_path\n\n# Check where NLTK is looking for its resources\nprint(\"NLTK data path:\", nltk.data.path)\n\n# Verify WordNet and other resources\ntry:\n    from nltk.corpus import wordnet\n    print(\"WordNet is successfully loaded!\")\nexcept Exception as e:\n    print(\"Error loading WordNet:\", e)\n\n# Define lemmatizer (after making sure WordNet is available)\nlemmatizer = nltk.WordNetLemmatizer()\n\n# Download NLTK resources\nnltk.download('wordnet')\nnltk.download('omw-1.4')  # For wordnet language support if needed\nnltk.download('stopwords')\n\nstop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()\nstemmer = PorterStemmer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T23:16:31.844006Z","iopub.execute_input":"2024-11-06T23:16:31.844462Z","iopub.status.idle":"2024-11-06T23:16:33.207520Z","shell.execute_reply.started":"2024-11-06T23:16:31.844422Z","shell.execute_reply":"2024-11-06T23:16:33.206490Z"}},"outputs":[{"name":"stdout","text":"Num GPUs Available:  2\nNLTK data path: ['/root/nltk_data', '/usr/share/nltk_data', '/usr/local/share/nltk_data', '/usr/lib/nltk_data', '/usr/local/lib/nltk_data']\nWordNet is successfully loaded!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import nltk\nprint(nltk.data.path)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T23:16:33.209516Z","iopub.execute_input":"2024-11-06T23:16:33.210763Z","iopub.status.idle":"2024-11-06T23:16:33.215522Z","shell.execute_reply.started":"2024-11-06T23:16:33.210723Z","shell.execute_reply":"2024-11-06T23:16:33.214470Z"}},"outputs":[{"name":"stdout","text":"['/root/nltk_data', '/usr/share/nltk_data', '/usr/local/share/nltk_data', '/usr/lib/nltk_data', '/usr/local/lib/nltk_data']\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Load the Sentiment140 dataset\ndf = pd.DataFrame()\n\ndata_path = '/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv'\ntry:\n    df = pd.read_csv(data_path, encoding='latin-1', header=None)\n    df.columns = ['polarity', 'id', 'date', 'query', 'user', 'text']  # Rename columns\n\n    # Filter out neutral polarity\n    df = df[df['polarity'] != 2]\n\n    # Map polarity to binary labels: 0 = negative, 1 = positive\n    df['polarity'] = df['polarity'].map({0: 0, 4: 1})\n\n    # Drop unnecessary columns\n    df = df[['polarity', 'text']]\n\n    print(df.head())  # Preview dataset\n\nexcept Exception as e:\n    print(f\"Error loading dataset: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T23:16:33.216708Z","iopub.execute_input":"2024-11-06T23:16:33.216966Z","iopub.status.idle":"2024-11-06T23:16:39.257539Z","shell.execute_reply.started":"2024-11-06T23:16:33.216937Z","shell.execute_reply":"2024-11-06T23:16:39.256440Z"}},"outputs":[{"name":"stdout","text":"   polarity                                               text\n0         0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n1         0  is upset that he can't update his Facebook by ...\n2         0  @Kenichan I dived many times for the ball. Man...\n3         0    my whole body feels itchy and like its on fire \n4         0  @nationwideclass no, it's not behaving at all....\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"# Preprocessing text\n\n# Fetch emoji and sentiment from csv\ndef load_emoji_sentiment(csv_file):\n    emoji_df = pd.read_csv(csv_file)\n    emoji_sentiment_dict = dict(zip(emoji_df['Emoji'], emoji_df['Sentiment']))\n    return emoji_sentiment_dict\n\n# Load the emoji sentiment dictionary at runtime\nemoji_sentiment_dict = load_emoji_sentiment('/kaggle/input/emoji-with-sentiments/emoji_sentiment.csv')\n\ndef replace_emojis(text):\n    for emoji, replacement in emoji_sentiment_dict.items():\n        text = text.replace(emoji, replacement)\n    return text\n\ndef remove_short_words(text):\n    return ' '.join([word for word in text.split() if len(word) >= 2])\n\ndef remove_stopwords(text):\n    return ' '.join([word for word in text.split() if word not in stop_words])\n\ndef apply_stemming(text):\n    return ' '.join([stemmer.stem(word) for word in text.split()])\n\ndef apply_lemmatization(text):\n    return ' '.join([lemmatizer.lemmatize(word) for word in text.split()])\n\n\ndef clean_text(text):\n    text = text.lower()  # Convert text to lowercase\n    text = replace_emojis(text)  # Replace emojis with their meaningful text\n    text = re.sub(r'http\\S+', 'url', text)  # Replace urls with 'url'\n    text = re.sub(r'\\b\\w*@\\w*\\.\\w*\\b', 'email', text)  # Replace email addresses with 'email'\n    text = re.sub(r'@\\w+', 'user', text)  # Replace user-mentions with 'user'\n    text = re.sub(r'#', '', text)  # Remove hashtag symbols\n    text = re.sub(r'\\d+', '', text)  # Remove numbers\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n    text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)  # Remove repeated characters\n    text = re.sub(r'\\b(\\w+)( \\1\\b)+', r'\\1', text)  # Remove consecutive duplicate words\n\n    # Handle repeated words without spaces\n    text = re.sub(r'(\\b\\w+)\\1+', r'\\1', text)\n\n    # Reduce consecutive duplicates\n    text = re.sub(r'(\\b\\w+)(\\1)+', r'\\1', text)  # Reduce repeated words\n    \n    text = remove_short_words(text)  # Remove short words\n    text = remove_stopwords(text)   # Remove stopwords\n    # text = apply_stemming(text)  # Apply stemming\n    # text = apply_lemmatization(text)  # Optional: apply both or just one\n    \n    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n    \n    return text\n\n\ndf['text'] = df['text'].apply(clean_text)\n\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T23:16:39.259970Z","iopub.execute_input":"2024-11-06T23:16:39.260323Z","iopub.status.idle":"2024-11-06T23:23:12.545050Z","shell.execute_reply.started":"2024-11-06T23:16:39.260287Z","shell.execute_reply":"2024-11-06T23:23:12.544029Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"   polarity                                               text\n0         0  user url aww thats bummer shoulda got david ca...\n1         0  upset cant update facebook texting might cry r...\n2         0  user dived many times ball managed save rest g...\n3         0                   whole body feels itchy like fire\n4         0                      user behaving im mad cant see","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>polarity</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>user url aww thats bummer shoulda got david ca...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>upset cant update facebook texting might cry r...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>user dived many times ball managed save rest g...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>whole body feels itchy like fire</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>user behaving im mad cant see</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# Prepare text data for neural network\nX = df['text']  # Text data\ny = df['polarity']  # Labels (0 = negative, 1 = positive)\n\n# Encode labels\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\n# Split dataset into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n\n# Tokenize the text data\ntokenizer = Tokenizer(num_words=5000, lower=True)\ntokenizer.fit_on_texts(X_train)\nX_train_sequences = tokenizer.texts_to_sequences(X_train)\nX_test_sequences = tokenizer.texts_to_sequences(X_test)\n\n# Pad the sequences to ensure uniform input size\nX_train_padded = pad_sequences(X_train_sequences, maxlen=100)\nX_test_padded = pad_sequences(X_test_sequences, maxlen=100)\n\n# Build the neural network model\nmodel = Sequential()\n\n# Add embedding layer (turns text into dense vectors)\n# model.add(Embedding(input_dim=5000, output_dim=128, input_length=100))\nmodel.add(Embedding(input_dim=5001, output_dim=128))\n\n# Add LSTM layer\nmodel.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n\n# Add dense layer with sigmoid activation for binary classification\nmodel.add(Dense(1, activation='sigmoid'))\n\n\n# Check GPU status at the start  (Optional)\n!nvidia-smi\n\n# Compile the model\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n# Use GPU if available and mixed precision (faster computation on GPU)\nwith tf.device('/GPU:0'):  # Use '/TPU:0' for TPU\n    # Train the model with larger batch size to utilize GPU/TPU efficiently\n    model.fit(X_train_padded, y_train, epochs=5, batch_size=128, validation_data=(X_test_padded, y_test), verbose=2)\n\n    # Monitor GPU usage after each epoch (Optional)\n    !nvidia-smi\n\n# Check GPU status after training (Optional)\n!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-06T23:23:12.546420Z","iopub.execute_input":"2024-11-06T23:23:12.546747Z","iopub.status.idle":"2024-11-07T01:05:38.770059Z","shell.execute_reply.started":"2024-11-06T23:23:12.546715Z","shell.execute_reply":"2024-11-07T01:05:38.768493Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"Wed Nov  6 23:24:04 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   65C    P0             31W /   70W |   14047MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   61C    P0             30W /   70W |     103MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\nEpoch 1/5\n10000/10000 - 1228s - 123ms/step - accuracy: 0.7751 - loss: 0.4682 - val_accuracy: 0.7852 - val_loss: 0.4519\nEpoch 2/5\n10000/10000 - 1218s - 122ms/step - accuracy: 0.7886 - loss: 0.4460 - val_accuracy: 0.7899 - val_loss: 0.4448\nEpoch 3/5\n10000/10000 - 1216s - 122ms/step - accuracy: 0.7941 - loss: 0.4366 - val_accuracy: 0.7919 - val_loss: 0.4411\nEpoch 4/5\n10000/10000 - 1217s - 122ms/step - accuracy: 0.7979 - loss: 0.4294 - val_accuracy: 0.7932 - val_loss: 0.4393\nEpoch 5/5\n10000/10000 - 1212s - 121ms/step - accuracy: 0.8016 - loss: 0.4230 - val_accuracy: 0.7942 - val_loss: 0.4388\nThu Nov  7 01:05:37 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   77C    P0             33W /   70W |   14061MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   66C    P0             32W /   70W |     103MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\nThu Nov  7 01:05:38 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   77C    P0             33W /   70W |   14061MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   66C    P0             32W /   70W |     103MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"print(X_train_padded.shape)  # Should be (num_samples, max_length)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T01:05:38.773801Z","iopub.execute_input":"2024-11-07T01:05:38.774310Z","iopub.status.idle":"2024-11-07T01:05:38.780993Z","shell.execute_reply.started":"2024-11-07T01:05:38.774246Z","shell.execute_reply":"2024-11-07T01:05:38.779868Z"}},"outputs":[{"name":"stdout","text":"(1280000, 100)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"# Evaluate the model\naccuracy = model.evaluate(X_test_padded, y_test, verbose=2)\nprint(f\"Model Accuracy: {accuracy[1]:.2f}\")\n\n# Save the model for later use\n# model.save('models/sentiment_analysis_model.h5')\nmodel.save('models/lstm_deep_learning_model.h5')\n\n\n# Save the tokenizer for later use (e.g., to process new text data)\n# joblib.dump(tokenizer, 'vectorizers/tokenizer.pkl')\njoblib.dump(tokenizer, 'lstm_deep_learning_tokenizer.pkl')\n\n# Monitor GPU usage after evaluation (Optional)\n!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T01:05:38.782415Z","iopub.execute_input":"2024-11-07T01:05:38.783257Z","iopub.status.idle":"2024-11-07T01:12:46.081730Z","shell.execute_reply.started":"2024-11-07T01:05:38.783222Z","shell.execute_reply":"2024-11-07T01:12:46.080668Z"}},"outputs":[{"name":"stdout","text":"10000/10000 - 413s - 41ms/step - accuracy: 0.7942 - loss: 0.4388\nModel Accuracy: 0.79\nThu Nov  7 01:12:45 2024       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |\n|-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n| N/A   77C    P0             34W /   70W |   14061MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n| N/A   68C    P0             32W /   70W |     103MiB /  15360MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n                                                                                         \n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# pip install optuna-integration[tfkeras]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T01:12:46.083487Z","iopub.execute_input":"2024-11-07T01:12:46.083836Z","iopub.status.idle":"2024-11-07T01:12:46.090146Z","shell.execute_reply.started":"2024-11-07T01:12:46.083797Z","shell.execute_reply":"2024-11-07T01:12:46.089179Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"import tensorflow as tf\nimport optuna\nfrom optuna.integration import TFKerasPruningCallback\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import mixed_precision  # Correct import without `experimental`\n\n# Enable mixed precision to boost performance on GPU\npolicy = mixed_precision.Policy('mixed_float16')\nmixed_precision.set_global_policy(policy)\n\n# Define the objective function for Optuna\ndef objective(trial):\n    # Hyperparameters to tune\n    embedding_dim = trial.suggest_int('embedding_dim', 64, 256)\n    lstm_units = trial.suggest_int('lstm_units', 64, 256)\n    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n    recurrent_dropout_rate = trial.suggest_float('recurrent_dropout_rate', 0.1, 0.5)\n    learning_rate = trial.suggest_float('learning_rate', 1e-4, 1e-2, log=True)\n    batch_size = trial.suggest_categorical('batch_size', [64, 128, 256])\n\n    # Build the model\n    model = Sequential()\n    # model.add(Embedding(input_dim=5000, output_dim=embedding_dim, input_length=100))\n    model.add(Embedding(input_dim=5001, output_dim=embedding_dim))\n    model.add(LSTM(lstm_units, dropout=dropout_rate, recurrent_dropout=recurrent_dropout_rate))\n    model.add(Dense(1, activation='sigmoid', dtype='float32'))  # Explicitly specify output dtype\n\n    # Compile the model with GPU-optimized Adam\n    model.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=learning_rate), metrics=['accuracy'])\n\n    # Train with the GPU if available\n    with tf.device('/GPU:0'):\n        history = model.fit(\n            X_train_padded, y_train,\n            epochs=5,  # Fewer epochs during tuning to save time\n            batch_size=batch_size,\n            validation_data=(X_test_padded, y_test),\n            verbose=2,\n            callbacks=[TFKerasPruningCallback(trial, 'val_accuracy')]\n        )\n    \n    # Return the validation accuracy of the last epoch\n    val_accuracy = history.history['val_accuracy'][-1]\n    return val_accuracy\n\n# Run the Optuna study\nstudy = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=20)  # Adjust `n_trials` for a balance between speed and thoroughness\n\n# Show best parameters\nprint(\"Best hyperparameters: \", study.best_params)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-07T10:52:47.394808Z","iopub.execute_input":"2024-11-07T10:52:47.395685Z","iopub.status.idle":"2024-11-07T10:53:01.696327Z","shell.execute_reply.started":"2024-11-07T10:52:47.395637Z","shell.execute_reply":"2024-11-07T10:53:01.694948Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/integration/tfkeras.py:5\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moptuna_integration\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtfkeras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TFKerasPruningCallback\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'optuna_integration'","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/integration/__init__.py:132\u001b[0m, in \u001b[0;36m_IntegrationModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:1006\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:688\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap_external>:883\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n","File \u001b[0;32m<frozen importlib._bootstrap>:241\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[0;34m(f, *args, **kwds)\u001b[0m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/integration/tfkeras.py:7\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(_INTEGRATION_IMPORT_ERROR_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtfkeras\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTFKerasPruningCallback\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n","\u001b[0;31mModuleNotFoundError\u001b[0m: \nCould not find `optuna-integration` for `tfkeras`.\nPlease run `pip install optuna-integration[tfkeras]`.","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moptuna\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mintegration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TFKerasPruningCallback\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Embedding, LSTM, Dense\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/integration/__init__.py:120\u001b[0m, in \u001b[0;36m_IntegrationModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    118\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_module(name)\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m--> 120\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/optuna/integration/__init__.py:134\u001b[0m, in \u001b[0;36m_IntegrationModule._get_module\u001b[0;34m(self, module_name)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(_INTEGRATION_IMPORT_ERROR_TEMPLATE\u001b[38;5;241m.\u001b[39mformat(module_name))\n","\u001b[0;31mModuleNotFoundError\u001b[0m: \nCould not find `optuna-integration` for `tfkeras`.\nPlease run `pip install optuna-integration[tfkeras]`."],"ename":"ModuleNotFoundError","evalue":"\nCould not find `optuna-integration` for `tfkeras`.\nPlease run `pip install optuna-integration[tfkeras]`.","output_type":"error"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}